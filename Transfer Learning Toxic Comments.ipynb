{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7001f184",
   "metadata": {},
   "source": [
    "### Load Libraries\n",
    "#### Pytorch Lightning, HuggingFace Bert, Pandas, SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1796640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import auroc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "cutoff = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edccc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This method is a batch method to load the augmented data files\n",
    "import re\n",
    "\n",
    "def process_file_to_dataframe(file_path):\n",
    "    # Regular expression to match lines with six comma-separated integers (either 0 or 1) at the end\n",
    "    pattern = re.compile(r\"(.*),(0|1),\\s*(0|1),\\s*(0|1),\\s*(0|1),\\s*(0|1),\\s*(0|1)$\")\n",
    "\n",
    "    # Preparing a list to store each row as a dictionary\n",
    "    data = []\n",
    "\n",
    "    # Reading the file and processing each line\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                match = pattern.search(line)\n",
    "                if match:\n",
    "                    # Creating a dictionary for each matched line\n",
    "                    row = {\n",
    "                        'comment_text': match.group(1).strip(),\n",
    "                        'toxic': int(match.group(2)),\n",
    "                        'severe_toxic': int(match.group(3)),\n",
    "                        'obscene': int(match.group(4)),\n",
    "                        'threat': int(match.group(5)),\n",
    "                        'insult': int(match.group(6)),\n",
    "                        'identity_hate': int(match.group(7))\n",
    "                    }\n",
    "                    data.append(row)\n",
    "    except UnicodeDecodeError:\n",
    "        # Try a different encoding in case of a decode error\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "            for line in file:\n",
    "                match = pattern.search(line)\n",
    "                if match:\n",
    "                    # Creating a dictionary for each matched line\n",
    "                    row = {\n",
    "                        'comment_text': match.group(1).strip(),\n",
    "                        'toxic': int(match.group(2)),\n",
    "                        'severe_toxic': int(match.group(3)),\n",
    "                        'obscene': int(match.group(4)),\n",
    "                        'threat': int(match.group(5)),\n",
    "                        'insult': int(match.group(6)),\n",
    "                        'identity_hate': int(match.group(7))\n",
    "                    }\n",
    "                    data.append(row)\n",
    "\n",
    "    # Creating a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "file_path = 'translated_text_with_labels_fr.txt'   # Replace with your actual file path\n",
    "augdata_fr = process_file_to_dataframe(file_path)\n",
    "\n",
    "# Now 'df' is a pandas DataFrame with the specified structure\n",
    "augdata_fr.insert(0, 'id', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c4534",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce712d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in the dataset\n",
    "toxiccomments_df = pd.read_csv(\"toxic_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4730737",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "See Data Augmentation French Translation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280057b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "##Append Augmented Data\n",
    "\n",
    "##toxiccomments_df = pd.concat([toxiccomments_df, augdata_ger], ignore_index=True)\n",
    "##toxiccomments_df = pd.concat([toxiccomments_df, augdata_sp], ignore_index=True)\n",
    "##toxiccomments_df = pd.concat([toxiccomments_df, augdata_fr], ignore_index=True)\n",
    "# Now 'appended_df' is the combined DataFrame\n",
    "print(toxiccomments_df.head())  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0474f",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Splitting up Data\n",
    "Creating Pytorch DataSet Class\n",
    "Creating Pytorch DataLoader Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efefed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split up our data\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initial split: 90% train, 10% temporary (for validation and test)\n",
    "train_df, temp_df = train_test_split(toxiccomments_df, test_size=0.1)\n",
    "\n",
    "# Second split of the temporary dataset: 50% validation, 50% test (5% of the original dataset each)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dec6f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143613, 8), (7979, 8), (7979, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Inspect the size of our datasets\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd4be75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id                                       comment_text  \\\n",
      "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
      "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
      "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
      "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
      "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
      "\n",
      "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0       0             0        0       0       0              0  \n",
      "2       0             0        0       0       0              0  \n",
      "3       0             0        0       0       0              0  \n",
      "8       0             0        0       0       0              0  \n",
      "10      0             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "long_strings = toxiccomments_df[toxiccomments_df['comment_text'].str.len() > 128]\n",
    "\n",
    "# Display the result\n",
    "print(long_strings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f65211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_c = toxiccomments_df.columns.tolist()[2:]\n",
    "\n",
    "summed_data = toxiccomments_df[labels_c].sum().sort_values()\n",
    "\n",
    "# Getting the colors from the rainbow palette, one for each bar\n",
    "palette = sns.color_palette(\"rainbow\", len(summed_data))\n",
    "\n",
    "# Creating the bar plot with individual colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=summed_data.index, x=summed_data.values, palette=palette)\n",
    "plt.title('Record Counts')\n",
    "plt.xlabel('Records')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7af761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_toxic = train_df[train_df[labels_c].sum(axis=1) > 0]\n",
    "train_clean = train_df[train_df[labels_c].sum(axis=1) == 0]\n",
    "\n",
    "\n",
    "train_df = pd.concat([  train_toxic,  train_clean.sample(30000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ebcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME, return_dict = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e87233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token_count = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b5c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pytorch Dataset Class\n",
    "##need to define our getitem in our pytorch dataset\n",
    "##provide parameters in how to load the data\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "\n",
    "  def __init__(\n",
    "    self, \n",
    "    data: pd.DataFrame, \n",
    "    tokenizer: BertTokenizer, \n",
    "    max_token_len: int = 128\n",
    "  ):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_token_len = max_token_len\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index: int):\n",
    "    \n",
    "    ##gets a single row\n",
    "    data_row = self.data.iloc[index]\n",
    "\n",
    "    comment_text = data_row.comment_text\n",
    "    labels = data_row[labels_c]\n",
    "    \n",
    "    ##parameters for Bert\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      comment_text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_token_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    return dict(        \n",
    "      ##text inputids, attention  \n",
    "      comment_text=comment_text,\n",
    "      input_ids=encoding[\"input_ids\"].flatten(), ##remove excess dimension\n",
    "      attention_mask=encoding[\"attention_mask\"].flatten(), ##remove excess dimension\n",
    "      labels=torch.FloatTensor(labels)) ##float tensor required by loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69de1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ToxicCommentsDataset(\n",
    "  train_df,\n",
    "  tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4750e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4395,  0.2536, -0.0164,  ..., -0.1966,  0.5110,  0.0689],\n",
      "         [ 0.6004, -0.2250,  0.2992,  ..., -0.1561,  0.1168,  0.1942],\n",
      "         [-0.0699, -0.1049,  0.0520,  ...,  0.0523, -0.1588,  0.2129],\n",
      "         ...,\n",
      "         [ 0.1794, -0.1084, -0.1187,  ...,  0.6084,  0.3537, -0.0576],\n",
      "         [ 0.5189, -0.0482,  0.1877,  ..., -0.0955, -0.0479,  0.2421],\n",
      "         [ 0.1709,  0.4509, -0.0793,  ..., -0.3501,  0.9191, -0.5921]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7063,  0.4875,  0.9999, -0.9938,  0.9680,  0.9220,  0.9903, -0.9924,\n",
      "         -0.9803, -0.6939,  0.9851,  0.9986, -0.9986, -0.9998,  0.8586, -0.9822,\n",
      "          0.9883, -0.5301, -0.9999, -0.8283, -0.4781, -0.9998,  0.2469,  0.9802,\n",
      "          0.9793,  0.0585,  0.9864,  0.9999,  0.9191, -0.3221,  0.2377, -0.9925,\n",
      "          0.8780, -0.9985,  0.1314,  0.1070,  0.8019, -0.1271,  0.8201, -0.9463,\n",
      "         -0.7594, -0.7919,  0.7308, -0.5193,  0.9426,  0.3260,  0.1086,  0.0143,\n",
      "          0.0086,  0.9996, -0.9726,  0.9972, -0.9961,  0.9950,  0.9963,  0.5145,\n",
      "          0.9963,  0.1480, -0.9989,  0.1614,  0.9686,  0.2540,  0.9252, -0.0617,\n",
      "          0.3165, -0.3044, -0.9278,  0.0746, -0.4813,  0.1865,  0.3903,  0.3203,\n",
      "          0.9885, -0.9065, -0.0274, -0.8891,  0.2370, -0.9999,  0.9626,  0.9999,\n",
      "          0.7922, -0.9997,  0.9951, -0.2285, -0.7606,  0.7269, -0.9988, -0.9994,\n",
      "          0.1570, -0.6542,  0.9277, -0.9874,  0.6553, -0.8957,  1.0000, -0.9638,\n",
      "         -0.1379,  0.3217,  0.9636, -0.8004, -0.7704,  0.9605,  0.9990, -0.9940,\n",
      "          0.9985,  0.7958, -0.9495, -0.8757,  0.8176,  0.0170,  0.9910, -0.9899,\n",
      "         -0.8674, -0.0546,  0.9487, -0.9165,  0.9906,  0.8761, -0.2368,  1.0000,\n",
      "         -0.1574,  0.9640,  0.9986,  0.8906, -0.8660, -0.2064, -0.6213,  0.9000,\n",
      "         -0.5331, -0.3313,  0.7702, -0.9919, -0.9981,  0.9995, -0.3318,  1.0000,\n",
      "         -0.9991,  0.9937, -0.9999, -0.8476, -0.8504, -0.0575, -0.9882,  0.1657,\n",
      "          0.9929,  0.0557, -0.9597, -0.8449,  0.6332, -0.9076,  0.5182,  0.6990,\n",
      "         -0.9669,  0.9936,  0.9975,  0.9490,  0.9894,  0.1861, -0.9563,  0.9324,\n",
      "          0.9832, -0.9994,  0.7557, -0.9937,  0.9991,  0.9760,  0.7713, -0.9956,\n",
      "          0.9999, -0.6781, -0.0874, -0.0600, -0.1904, -0.9989,  0.4935,  0.4065,\n",
      "          0.7936,  0.9993, -0.9963,  0.9993,  0.9004,  0.0942,  0.7508,  0.9988,\n",
      "         -0.9963, -0.9836, -0.9879,  0.2017,  0.6631,  0.7994,  0.4239,  0.9676,\n",
      "          0.9984,  0.6998, -0.9977, -0.3786,  0.9772, -0.1280,  1.0000, -0.3250,\n",
      "         -0.9997, -0.8273,  0.9478,  0.9910, -0.3235,  0.9861, -0.7240, -0.2742,\n",
      "          0.9878, -0.9901,  0.9980,  0.1145,  0.8936,  0.9010,  0.9949, -0.8812,\n",
      "         -0.1006,  0.1588, -0.7661,  0.9999, -0.9995, -0.3067,  0.4703, -0.9928,\n",
      "         -0.9982,  0.9886,  0.0542, -0.9078, -0.1935,  0.7706,  0.1807,  0.9350,\n",
      "          0.9908, -0.6531, -0.6214, -0.9998, -0.9977, -0.8635, -0.9612,  0.0188,\n",
      "          0.6283, -0.3339, -0.9099, -0.9979,  0.9766,  0.8531, -0.9393, -0.1225,\n",
      "         -0.6998, -0.9982,  0.6342, -0.8804, -0.9983,  0.9994, -0.8295,  0.9965,\n",
      "          0.9814, -0.9952,  0.8586, -0.9988, -0.0666, -0.9948,  0.3440,  0.6532,\n",
      "         -0.8286, -0.0044,  0.9924, -0.9729, -0.8682,  0.8484, -0.9999,  0.9495,\n",
      "         -0.1826,  0.9991,  0.8558,  0.1308,  0.9870,  0.9288, -0.9829, -0.9998,\n",
      "          0.9363,  0.9441, -0.9942, -0.1393,  0.9999, -0.9981, -0.8287, -0.9538,\n",
      "         -0.9962, -0.9996,  0.2705, -0.8602,  0.1838,  0.9871,  0.3848,  0.2563,\n",
      "          0.9951,  0.9953,  0.2733, -0.2963,  0.0275, -0.9792, -0.9666,  0.7690,\n",
      "          0.1806, -1.0000,  0.9998, -0.9957,  0.9939,  0.9733, -0.9956,  0.8619,\n",
      "          0.0996, -0.9711, -0.0206,  0.9999,  0.9853,  0.0157,  0.2087,  0.9491,\n",
      "         -0.2971,  0.6897, -0.8493, -0.6673,  0.1326, -0.9304,  0.9936,  0.8358,\n",
      "         -0.9916,  0.9959,  0.0908,  0.7795, -0.7899,  0.8456,  0.9915, -0.0555,\n",
      "         -0.3607,  0.1068, -0.3570, -0.9824,  0.1523, -0.9977, -0.4206,  0.9236,\n",
      "          0.9909, -0.9927,  0.9940, -0.1118,  0.9263, -0.9980,  1.0000, -0.9981,\n",
      "          0.0463,  0.7851, -0.9300, -0.6443,  0.9933,  0.9893,  0.9833, -0.8166,\n",
      "         -0.6614,  0.9016,  0.9773, -0.9779, -0.0038, -0.9993, -0.7618,  0.9961,\n",
      "          0.9969,  0.0721, -0.0559, -0.9979,  0.9633, -0.8801, -0.9220, -0.0102,\n",
      "         -0.8683,  0.8339,  0.9981, -0.6305,  0.7133,  0.1007, -0.9902,  0.9125,\n",
      "          0.8141,  0.9998, -0.9708,  0.5041,  0.9905, -0.2101, -0.6762,  0.5851,\n",
      "          0.9991, -0.9840, -0.2196, -0.9995,  0.0560, -0.8280,  0.0226, -0.5787,\n",
      "          0.1189, -0.8626,  0.9726,  0.2834,  0.6924, -0.4288,  0.9812, -0.2073,\n",
      "         -0.0424, -0.2898, -0.2404,  0.5216,  0.3019,  0.9865, -0.9764,  0.9996,\n",
      "         -0.1856, -1.0000, -0.9968, -0.7735, -0.9995,  0.8171, -0.9961,  0.9888,\n",
      "          0.9381, -0.9982, -0.9991, -0.9984, -0.9953,  0.8696,  0.7189, -0.0474,\n",
      "          0.2841,  0.1023,  0.0839, -0.1844, -0.0775, -0.9630, -0.6930, -0.9984,\n",
      "          0.7365, -1.0000, -0.7391,  0.9973, -0.9969, -0.9308, -0.9190, -0.9295,\n",
      "         -0.8838,  0.4410,  0.9880, -0.0187, -0.6419, -0.9995,  0.9888, -0.8774,\n",
      "          0.1735, -0.8565, -0.9785,  0.9996,  0.8970, -0.2895, -0.0658, -0.9987,\n",
      "          0.9915, -0.9651, -0.9112, -0.9825,  0.0925, -0.9517, -0.9998,  0.0923,\n",
      "          0.9963,  0.9959,  0.9816,  0.3076, -0.3356, -0.9621,  0.1017, -0.9999,\n",
      "          0.8803,  0.8737, -0.9860, -0.8302,  0.9945,  0.9807, -0.9648, -0.9789,\n",
      "          0.9454,  0.5919,  0.9668, -0.5105, -0.4244,  0.2924,  0.0060, -0.9896,\n",
      "         -0.9208,  0.9962, -0.9992,  0.9809,  0.9953,  0.9985, -0.1679,  0.0150,\n",
      "         -0.9890, -0.9909, -0.6277,  0.3568, -0.9999,  0.9999, -1.0000,  0.6964,\n",
      "         -0.7520,  0.9213,  0.9897, -0.4849, -0.9999, -0.9997,  0.3884, -0.0283,\n",
      "          0.9908,  0.3553,  0.2244, -0.6663, -0.1636,  0.9970, -0.8853, -0.8285,\n",
      "         -0.9980,  0.9996,  0.7000, -0.9986,  0.9966, -0.9995,  0.9150,  0.9802,\n",
      "          0.8662,  0.9815, -0.9989,  1.0000, -0.9997,  0.9982, -1.0000, -0.9989,\n",
      "          0.9998, -0.9920, -0.7686, -0.9997, -0.9981,  0.8270,  0.1291, -0.4959,\n",
      "          0.9908, -0.9998, -0.9986,  0.2916, -0.9502, -0.8741,  0.9959, -0.6499,\n",
      "          0.9930, -0.1374,  0.9710,  0.3020,  0.9975,  0.9959, -0.8716, -0.7342,\n",
      "         -0.9945,  0.9853, -0.6357,  0.3316,  0.9599,  0.0985, -0.6930,  0.3366,\n",
      "         -0.9972,  0.3664, -0.2543,  0.9328,  0.9309,  0.8489, -0.0991, -0.6304,\n",
      "         -0.2366, -0.9945,  0.5581, -0.9995,  0.9809, -0.9585,  0.0370, -0.4534,\n",
      "          0.4268, -0.9751,  0.9995,  0.9985, -0.9970,  0.0906,  0.9903, -0.8157,\n",
      "          0.9807, -0.9932,  0.0276,  0.9645, -0.7478,  0.9846,  0.2325, -0.0375,\n",
      "          0.9723, -0.9960, -0.9342, -0.7086,  0.3570,  0.2058, -0.9737,  0.0578,\n",
      "          0.9894, -0.2040, -0.9997,  0.9472, -0.9994, -0.1139,  0.9779, -0.0376,\n",
      "          0.9999, -0.7879,  0.1263,  0.1961, -0.9998, -0.9990,  0.0232, -0.1049,\n",
      "         -0.9704,  0.9992, -0.0150,  0.9188, -0.9998,  0.2326,  0.9960,  0.2835,\n",
      "          0.8402, -0.8198, -0.9660, -0.9739, -0.6589,  0.0217,  0.9277, -0.9906,\n",
      "         -0.8521, -0.8565,  0.9999, -0.9977, -0.9001, -0.9882,  0.5337,  0.9101,\n",
      "          0.4539,  0.0652, -0.9437,  0.9551, -0.9458,  0.9969, -0.9957, -0.9967,\n",
      "          0.9998,  0.6827, -0.9952, -0.0930, -0.3990,  0.2730,  0.1855,  0.7937,\n",
      "         -0.9512, -0.1451, -0.9982,  0.8335, -0.9059, -0.9916, -0.5660, -0.3786,\n",
      "         -0.9948,  0.9950,  0.9684,  0.9999, -0.9998,  0.8827,  0.0571,  0.9992,\n",
      "          0.0307, -0.6629,  0.9244,  0.9995, -0.7324,  0.8856, -0.0962,  0.0249,\n",
      "          0.1881, -0.6435,  0.9969, -0.9556,  0.1620, -0.9747, -0.9999,  0.9999,\n",
      "         -0.0483,  0.9909,  0.2915,  0.8657, -0.8983,  0.9826, -0.9785, -0.9122,\n",
      "         -1.0000,  0.1611, -0.9973, -0.9922,  0.0735,  0.9890, -0.9996, -0.9930,\n",
      "         -0.4599, -1.0000,  0.9500, -0.9905, -0.8983, -0.9920,  0.9980, -0.4508,\n",
      "         -0.6785,  0.9812, -0.9808,  0.9599,  0.9523, -0.2220,  0.2329,  0.0582,\n",
      "         -0.7999, -0.9945, -0.9295, -0.9625,  0.8767, -0.9908, -0.8858,  0.9968,\n",
      "          0.9907, -0.9991, -0.9962,  0.9964, -0.0984,  0.9925, -0.5625, -0.9998,\n",
      "         -0.9999,  0.1097, -0.0143,  0.9962, -0.3277,  0.9854,  0.7772, -0.4981,\n",
      "          0.5027, -0.5811, -0.2844, -0.4310, -0.1575,  1.0000, -0.8537,  0.9935]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_row = toxiccomments_df.iloc[31]\n",
    "sample_comment = sample_row.comment_text\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "encoded_input = tokenizer(sample_comment, return_tensors='pt')\n",
    "output = bert_model(**encoded_input)\n",
    "\n",
    "\n",
    "##This is what highly contextualized word embeddings look like \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f081180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class handles data loading processes for training, validation, and testing\n",
    "class ToxicCommentDataModule(pl.LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size # Define batch size for DataLoader\n",
    "    self.train_df = train_df # Dataframe for training data\n",
    "    self.val_df = val_df # Dataframe for validation data\n",
    "    self.test_df = test_df # Dataframe for test data\n",
    "    self.tokenizer = tokenizer # Tokenizer for text data\n",
    "    self.max_token_len = max_token_len # Maximum token length for tokenizer\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    # Create datasets for training, validation, and testing\n",
    "    self.train_dataset = ToxicCommentsDataset(\n",
    "      self.train_df,\n",
    "      self.tokenizer,\n",
    "      self.max_token_len\n",
    "    )\n",
    "\n",
    "    self.val_dataset = ToxicCommentsDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "    )\n",
    "\n",
    "    self.test_dataset = ToxicCommentsDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.max_token_len\n",
    "    )\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    # DataLoader for training data with shuffling\n",
    "    return DataLoader(\n",
    "      self.train_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=0 # Number of workers for loading data\n",
    "    )\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    # DataLoader for validation data\n",
    "    return DataLoader(\n",
    "      self.val_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=0 # Number of workers for loading data\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    # DataLoader for test data\n",
    "    return DataLoader(\n",
    "      self.test_dataset,\n",
    "      batch_size=self.batch_size,\n",
    "      num_workers=0 # Number of workers for loading data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c9d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "data_module = ToxicCommentDataModule(\n",
    "  train_df,\n",
    "  val_df, test_df,\n",
    "  tokenizer, batch_size = BATCH_SIZE)\n",
    "\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ae3b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1395"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bd01e",
   "metadata": {},
   "source": [
    "# Model Selection, Training, Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb50d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicCommentTagger(pl.LightningModule):\n",
    "  def __init__(self, n_classes: int, steps_per_epoch=None, n_epochs=None):\n",
    "    super().__init__()\n",
    "    self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True) # Load pretrained BERT model\n",
    "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes) # Define a classifier layer\n",
    "    self.steps_per_epoch = steps_per_epoch # Set steps per epoch for training\n",
    "    self.n_epochs = n_epochs # Set number of epochs for training\n",
    "    self.criterion = nn.BCELoss() # Binary Cross Entropy loss for binary classification\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.bert(input_ids, attention_mask=attention_mask) # BERT model processing\n",
    "    output = self.classifier(output.pooler_output) # Apply classifier\n",
    "    output = torch.sigmoid(output) # Apply sigmoid activation\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(output, labels) # Calculate loss if labels are provided\n",
    "    return loss, output\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Extract input IDs, attention masks, and labels from batch\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels) # Perform a forward pass\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True) # Log training loss\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    # Same as training_step, but for validation data\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True) # Log validation loss\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    # Same as training_step, but for test data\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True) # Log test loss\n",
    "    return loss\n",
    "\n",
    "  def training_epoch_end(self, outputs):\n",
    "    # Process at the end of each training epoch\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "      for out_labels in output[\"labels\"].detach().cpu():\n",
    "        labels.append(out_labels)\n",
    "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "        predictions.append(out_predictions)\n",
    "\n",
    "    labels = torch.stack(labels).int()\n",
    "    predictions = torch.stack(predictions)\n",
    "\n",
    "    # Calculate and log ROC AUC for each class\n",
    "    for i, name in enumerate(labels_c):\n",
    "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5) # Define optimizer\n",
    "\n",
    "    # Scheduler settings for learning rate adjustment\n",
    "    warmup_steps = self.steps_per_epoch // 3\n",
    "    total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=warmup_steps, \n",
    "      num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    scheduler_config = {\n",
    "        'scheduler': scheduler,\n",
    "        'interval': 'step',  # 'step' or 'epoch' based on preference\n",
    "        'frequency': 1\n",
    "    }\n",
    "\n",
    "    return {'optimizer': optimizer, 'lr_scheduler': scheduler_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3b7676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For Model Evaluation\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"toxic-comments_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e41417",
   "metadata": {},
   "source": [
    "### Initialize the Model, run .fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e053bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "# Assuming ToxicCommentTagger, train_df, BATCH_SIZE, N_EPOCHS, logger, and data_module are defined\n",
    "\n",
    "# Initialize your model\n",
    "model = ToxicCommentTagger(n_classes=6, steps_per_epoch=len(train_df) // BATCH_SIZE, n_epochs=N_EPOCHS)\n",
    "\n",
    "# Add LearningRateMonitor to the callbacks\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')  # or 'epoch'\n",
    "\n",
    "# Initialize Trainer with the LearningRateMonitor callback\n",
    "trainer = pl.Trainer(    logger=logger,    callbacks=[lr_monitor],    max_epochs=N_EPOCHS,    accelerator='gpu',    devices=1)\n",
    "\n",
    "# Fit the model\n",
    "##trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f062b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ckpt_file_path, test_df, tokenizer, max_token_count, labels_c, cutoff=0.5, average_method='macro'):\n",
    "    # Load the trained model from the checkpoint file path\n",
    "    trained_model = ToxicCommentTagger.load_from_checkpoint(ckpt_file_path, n_classes=len(labels_c))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    trained_model = trained_model.to(device)\n",
    "\n",
    "    val_dataset = ToxicCommentsDataset(test_df, tokenizer, max_token_len=max_token_count)\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(val_dataset):\n",
    "            _, prediction = trained_model(\n",
    "                item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
    "                item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "            )\n",
    "            predictions.append(prediction.flatten())\n",
    "            labels.append(item[\"labels\"].int())\n",
    "\n",
    "    predictions = torch.stack(predictions).detach().cpu()\n",
    "    labels = torch.stack(labels).detach().cpu()\n",
    "\n",
    "    y_pred = np.where(predictions.numpy() > cutoff, 1, 0)\n",
    "    y_true = labels.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=average_method, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=average_method, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=average_method, zero_division=0)\n",
    "\n",
    "    classification_rep = classification_report(y_true, y_pred, target_names=labels_c, zero_division=0)\n",
    "    \n",
    "    return classification_rep, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ada42e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7979/7979 [02:50<00:00, 46.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.60      0.99      0.75       728\n",
      " severe_toxic       0.87      0.93      0.90        67\n",
      "      obscene       0.87      0.98      0.92       408\n",
      "       threat       0.77      0.94      0.85        18\n",
      "       insult       0.86      0.97      0.91       386\n",
      "identity_hate       0.78      0.98      0.87        66\n",
      "\n",
      "    micro avg       0.72      0.98      0.83      1673\n",
      "    macro avg       0.79      0.96      0.87      1673\n",
      " weighted avg       0.75      0.98      0.84      1673\n",
      "  samples avg       0.09      0.09      0.09      1673\n",
      "\n",
      "Accuracy: 0.93\n",
      "Precision: 0.79\n",
      "Recall: 0.96\n",
      "F1: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt_file_path = \"C:\\\\Users\\\\salil\\\\lightning_logs\\\\toxic-comments_da\\\\version_0\\\\checkpoints\\\\epoch=14-step=27675.ckpt\"\n",
    "\n",
    "\n",
    "c_report, accuracy, precision, recall, f1 = evaluate_model(ckpt_file_path, test_df, tokenizer, max_token_count, labels_c)\n",
    "print(c_report)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "118a1de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.60      0.99      0.75       728\n",
      " severe_toxic       0.87      0.93      0.90        67\n",
      "      obscene       0.87      0.98      0.92       408\n",
      "       threat       0.77      0.94      0.85        18\n",
      "       insult       0.86      0.97      0.91       386\n",
      "identity_hate       0.78      0.98      0.87        66\n",
      "\n",
      "    micro avg       0.72      0.98      0.83      1673\n",
      "    macro avg       0.79      0.96      0.87      1673\n",
      " weighted avg       0.75      0.98      0.84      1673\n",
      "  samples avg       0.09      0.09      0.09      1673\n",
      "\n",
      "Accuracy: 0.93\n",
      "Precision: 0.79\n",
      "Recall: 0.96\n",
      "F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ckpt_file_path = \"C:\\\\Users\\\\salil\\\\lightning_logs\\\\toxic-comments_tl\\\\version_0\\\\checkpoints\\\\epoch=14-step=34515.ckpt\"\n",
    "\n",
    "c_report, accuracy, precision, recall, f1 = evaluate_model(ckpt_file_path, test_df, tokenizer, max_token_count, labels_c)\n",
    "print(c_report)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76754362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7979/7979 [02:49<00:00, 47.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.56      0.94      0.70       728\n",
      " severe_toxic       0.46      0.46      0.46        67\n",
      "      obscene       0.72      0.82      0.77       408\n",
      "       threat       0.41      0.50      0.45        18\n",
      "       insult       0.70      0.75      0.73       386\n",
      "identity_hate       0.48      0.50      0.49        66\n",
      "\n",
      "    micro avg       0.61      0.83      0.70      1673\n",
      "    macro avg       0.56      0.66      0.60      1673\n",
      " weighted avg       0.62      0.83      0.70      1673\n",
      "  samples avg       0.08      0.08      0.08      1673\n",
      "\n",
      "Accuracy: 0.88\n",
      "Precision: 0.56\n",
      "Recall: 0.66\n",
      "F1: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ckpt_file_path = \"C:\\\\Users\\\\salil\\\\lightning_logs\\\\toxic-comments_d\\\\version_0\\\\checkpoints\\\\epoch=11-step=11256.ckpt\"\n",
    "\n",
    "c_report, accuracy, precision, recall, f1 = evaluate_model(ckpt_file_path, test_df, tokenizer, max_token_count, labels_c)\n",
    "print(c_report)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f008032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: [9.9938262e-01 7.8406436e-03 1.9777205e-03 7.9431254e-03 7.7068270e-04\n",
      " 1.3358864e-01]\n"
     ]
    }
   ],
   "source": [
    "trained_model = ToxicCommentTagger.load_from_checkpoint(ckpt_file_path, n_classes=len(labels_c))\n",
    "\n",
    "\n",
    "test_comment = \"type in your test comment here to test toxic classifier\"\n",
    "\n",
    "\n",
    "\n",
    "encoding = tokenizer.encode_plus(\n",
    "  test_comment,\n",
    "  add_special_tokens=True,\n",
    "  max_length=512,\n",
    "  return_token_type_ids=False,\n",
    "  padding=\"max_length\",\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "_, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
    "test_prediction = test_prediction.detach().numpy()\n",
    "\n",
    "for label, prediction in zip(labels_c, test_prediction):\n",
    "  print(f\"{label}: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bef316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
